{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40aa4557-7262-4f86-8738-d117de25c754",
   "metadata": {},
   "source": [
    "## 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5208c236-cf77-48e7-a763-5507cbb8c2b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불러온 파일: ['titanic/train.csv', 'titanic/test.csv']\n",
      "통합 후 데이터 크기: (1309, 13)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "\n",
    "# 데이터 불러오기\n",
    "DATA_DIR = 'titanic'\n",
    "data_files = sorted(glob.glob(DATA_DIR + \"/*.csv\"), reverse=True)\n",
    "print(\"불러온 파일:\", data_files)\n",
    "\n",
    "# train, test 각각 읽기\n",
    "train_df = pd.read_csv(data_files[0])\n",
    "test_df = pd.read_csv(data_files[1])\n",
    "\n",
    "n_train = len(train_df)\n",
    "n_test = len(test_df)\n",
    "\n",
    "# 두 데이터 합치기 \n",
    "df = pd.concat([train_df, test_df], sort=False).reset_index(drop=True)\n",
    "print(\"통합 후 데이터 크기:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "53d96246-687b-4b3b-9a1f-b2615e57bf0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0     0.00\n",
      "PassengerId    0.00\n",
      "Survived       0.00\n",
      "Pclass         0.00\n",
      "Name           0.00\n",
      "Sex            0.00\n",
      "Age           20.09\n",
      "SibSp          0.00\n",
      "Parch          0.00\n",
      "Ticket         0.00\n",
      "Fare           0.08\n",
      "Cabin         77.46\n",
      "Embarked       0.15\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "print(df.isnull().sum() / len(df) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2773eaee-753f-4875-8b55-bd342b3573f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>61</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Icard, Miss. Amelie</td>\n",
       "      <td>female</td>\n",
       "      <td>38.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113572</td>\n",
       "      <td>80.00</td>\n",
       "      <td>B28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>829</td>\n",
       "      <td>830</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Stone, Mrs. George Nelson (Martha Evelyn)</td>\n",
       "      <td>female</td>\n",
       "      <td>62.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113572</td>\n",
       "      <td>80.00</td>\n",
       "      <td>B28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  PassengerId  Survived  Pclass  \\\n",
       "61           61           62         1       1   \n",
       "829         829          830         1       1   \n",
       "\n",
       "                                          Name     Sex   Age  SibSp  Parch  \\\n",
       "61                         Icard, Miss. Amelie  female 38.00      0      0   \n",
       "829  Stone, Mrs. George Nelson (Martha Evelyn)  female 62.00      0      0   \n",
       "\n",
       "     Ticket  Fare Cabin Embarked  \n",
       "61   113572 80.00   B28      NaN  \n",
       "829  113572 80.00   B28      NaN  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"Embarked\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4eece1d1-7e00-4b3f-985c-f78af00c9658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>152</td>\n",
       "      <td>1044</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Storey, Mr. Thomas</td>\n",
       "      <td>male</td>\n",
       "      <td>60.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3701</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  PassengerId  Survived  Pclass                Name   Sex  \\\n",
       "1043         152         1044         0       3  Storey, Mr. Thomas  male   \n",
       "\n",
       "       Age  SibSp  Parch Ticket  Fare Cabin Embarked  \n",
       "1043 60.50      0      0   3701   NaN   NaN        S  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"Fare\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "96f09906-bbc6-4886-956a-0ee6ef1ef6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age: Pclass 기준 평균으로 채움\n",
    "df[\"Age\"] = df[\"Age\"].fillna(df.groupby(\"Pclass\")[\"Age\"].transform(\"mean\"))\n",
    "\n",
    "# Embarked: 결측을 'S'로 채움\n",
    "df[\"Embarked\"] = df[\"Embarked\"].fillna(\"S\")\n",
    "\n",
    "# Fare: 결측을 3등급의 평균으로 채움\n",
    "mean_fare_pclass3 = df.loc[df[\"Pclass\"] == 3, \"Fare\"].mean()\n",
    "df[\"Fare\"] = df[\"Fare\"].fillna(mean_fare_pclass3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "61db05c9-3b6e-4da0-9117-6b650d888720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1309 entries, 0 to 1308\n",
      "Data columns (total 13 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Unnamed: 0   1309 non-null   int64  \n",
      " 1   PassengerId  1309 non-null   int64  \n",
      " 2   Survived     1309 non-null   int64  \n",
      " 3   Pclass       1309 non-null   int64  \n",
      " 4   Name         1309 non-null   object \n",
      " 5   Sex          1309 non-null   object \n",
      " 6   Age          1309 non-null   float64\n",
      " 7   SibSp        1309 non-null   int64  \n",
      " 8   Parch        1309 non-null   int64  \n",
      " 9   Ticket       1309 non-null   object \n",
      " 10  Fare         1309 non-null   float64\n",
      " 11  Cabin        295 non-null    object \n",
      " 12  Embarked     1309 non-null   object \n",
      "dtypes: float64(2), int64(6), object(5)\n",
      "memory usage: 133.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "89e2beda-6018-460b-85fb-29ff2909d738",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_columns = [\"PassengerId\", \"Pclass\", \"Name\", \"Sex\",\n",
    "                  \"Ticket\", \"Cabin\", \"Embarked\"]\n",
    "numeric_columns = [\"Age\", \"SibSp\", \"Parch\", \"Fare\"]\n",
    "\n",
    "for col in object_columns:\n",
    "    df[col] = df[col].astype(object)\n",
    "for col in numeric_columns:\n",
    "    df[col] = df[col].astype(float)\n",
    "\n",
    "df[\"SibSp\"] = df[\"SibSp\"].astype(int)\n",
    "df[\"Parch\"] = df[\"Parch\"].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "78edc424-bcf2-4c91-b644-dc3598817bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_and_get(ldf, rdf, on=None, how=\"inner\", index=None):\n",
    "    if index is True:\n",
    "        return pd.merge(ldf, rdf, how=how, left_index=True, right_index=True)\n",
    "    else:\n",
    "        return pd.merge(ldf, rdf, how=how, on=on)\n",
    "\n",
    "one_hot_df = merge_and_get(df, pd.get_dummies(df[\"Sex\"], prefix=\"Sex\"), index=True)\n",
    "one_hot_df = merge_and_get(one_hot_df, pd.get_dummies(df[\"Pclass\"], prefix=\"Pclass\"), index=True)\n",
    "one_hot_df = merge_and_get(one_hot_df, pd.get_dummies(df[\"Embarked\"], prefix=\"Embarked\"), index=True)\n",
    "\n",
    "# 원본 범주형 제거\n",
    "one_hot_df = one_hot_df.drop(columns=[\"Sex\", \"Pclass\", \"Embarked\"])\n",
    "\n",
    "# 학습에 의미 없는 텍스트 컬럼 제거\n",
    "drop_cols = [\"PassengerId\", \"Name\", \"Ticket\", \"Cabin\"]\n",
    "one_hot_df = one_hot_df.drop(columns=drop_cols, errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9033cfe1-5583-4094-bd30-2e0c5a67c108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 크기: (891, 13)\n",
      "Test 크기: (418, 13)\n"
     ]
    }
   ],
   "source": [
    "# 위에서 기록한 n_train, n_test 사용\n",
    "x_train = one_hot_df.iloc[:n_train, :].copy()\n",
    "x_test = one_hot_df.iloc[n_train:, :].copy()\n",
    "\n",
    "y_train = train_df[\"Survived\"].reset_index(drop=True)\n",
    "y_test = test_df[\"Survived\"].reset_index(drop=True)\n",
    "\n",
    "# 입력에서는 Survived 제거\n",
    "x_train = x_train.drop(columns=['Survived'], errors='ignore')\n",
    "x_test = x_test.drop(columns=['Survived'], errors='ignore')\n",
    "\n",
    "print(\"Train 크기:\", x_train.shape)\n",
    "print(\"Test 크기:\", x_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794fa2cb-64a0-4d5b-a49f-47b09f7015dd",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1f402eb1-c89f-4c2a-aab5-0f586220a715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Cutoff from Train\n",
      "Threshold   0.35\n",
      "Accuracy    0.78\n",
      "Precision   0.68\n",
      "Recall      0.81\n",
      "F1          0.74\n",
      "Name: 25, dtype: float64\n",
      "\n",
      "Linear Regression 성능 (using best cutoff)\n",
      "Cutoff: 0.35\n",
      "Accuracy : 0.730\n",
      "Precision: 0.613\n",
      "Recall   : 0.772\n",
      "F1 Score : 0.683\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# 모델 학습 \n",
    "lr = LinearRegression()\n",
    "lr.fit(x_train, y_train)\n",
    "\n",
    "# train 데이터로 cutoff 탐색\n",
    "y_train_pred = lr.predict(x_train)\n",
    "\n",
    "thresholds = np.arange(0.1, 0.9, 0.01)\n",
    "train_results = []\n",
    "\n",
    "for t in thresholds:\n",
    "    y_train_bin = (y_train_pred >= t).astype(int)\n",
    "    acc = accuracy_score(y_train, y_train_bin)\n",
    "    prec = precision_score(y_train, y_train_bin)\n",
    "    rec = recall_score(y_train, y_train_bin)\n",
    "    f1 = f1_score(y_train, y_train_bin)\n",
    "    train_results.append([t, acc, prec, rec, f1])\n",
    "\n",
    "# DataFrame 정리\n",
    "train_result_df = pd.DataFrame(train_results, columns=[\"Threshold\", \"Accuracy\", \"Precision\", \"Recall\", \"F1\"])\n",
    "\n",
    "# train 기준으로 best cutoff 선택\n",
    "best_row = train_result_df.loc[train_result_df[\"F1\"].idxmax()]\n",
    "best_t = best_row[\"Threshold\"]\n",
    "\n",
    "print(\"Best Cutoff from Train\")\n",
    "print(best_row)\n",
    "\n",
    "# 선택된 cutoff로 test 데이터 예측\n",
    "y_test_pred = lr.predict(x_test)\n",
    "y_test_bin = (y_test_pred >= best_t).astype(int)\n",
    "\n",
    "# test 성능 평가\n",
    "test_acc = accuracy_score(y_test, y_test_bin)\n",
    "test_prec = precision_score(y_test, y_test_bin)\n",
    "test_rec = recall_score(y_test, y_test_bin)\n",
    "test_f1 = f1_score(y_test, y_test_bin)\n",
    "\n",
    "print(f\"\\nLinear Regression 성능 (using best cutoff)\")\n",
    "print(f\"Cutoff: {best_t:.2f}\")\n",
    "print(f\"Accuracy : {test_acc:.3f}\")\n",
    "print(f\"Precision: {test_prec:.3f}\")\n",
    "print(f\"Recall   : {test_rec:.3f}\")\n",
    "print(f\"F1 Score : {test_f1:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbaff38-23fe-4ddd-b38e-757c19c58c2c",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "323a1fd6-f7b4-45cd-9271-8ef694231fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression 성능\n",
      "Accuracy : 0.770\n",
      "Precision: 0.704\n",
      "Recall   : 0.677\n",
      "F1 Score : 0.690\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# 로지스틱 회귀 모델 학습 \n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "log_reg.fit(x_train, y_train)\n",
    "\n",
    "# 예측 \n",
    "y_pred_proba = log_reg.predict_proba(x_test)[:, 1]  # 생존(1)일 확률\n",
    "y_pred = (y_pred_proba >= 0.5).astype(int)\n",
    "\n",
    "# 성능 평가\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Logistic Regression 성능\")\n",
    "print(f\"Accuracy : {acc:.3f}\")\n",
    "print(f\"Precision: {prec:.3f}\")\n",
    "print(f\"Recall   : {rec:.3f}\")\n",
    "print(f\"F1 Score : {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcde823-6660-4113-b428-f57979d90620",
   "metadata": {},
   "source": [
    "### 두 모델을 비교해 봅시다. 어느 모델이 성능이 나은가요?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716e9861-10cf-4233-b80f-831c70c1d7be",
   "metadata": {},
   "source": [
    "두 모델은 전반적으로 비슷한 수준의 분류 성능을 보이지만 세부적인 성능 지표와 안정성 측면에서 차이를 보인다.\n",
    "선형 회귀는 F1 Score가 0.68로 로지스틱 회귀(0.69)와 거의 유사한 수준이었으며 Recall(재현율)이 0.77로 높게 나타났다. 이는 실제 생존자를 놓치지 않고 잘 예측하는 경향을 보이며 민감도가 중요한 상황에서 유리하게 작용할 수 있다.\n",
    "반면 Accuracy(정확도)와 Precision(정밀도)은 로지스틱 회귀가 더 높은 수치를 기록했다. 로지스틱 회귀는 모델이 생존이라고 예측한 경우 실제로 생존일 확률이 더 높다는 점에서 신뢰도가 높다. 또한 F1 Score가 비슷한 수준을 유지하면서 전체적인 지표 간의 균형이 보다 안정적으로 나타났다.\n",
    "종합적으로 볼 때 선형 회귀는 재현율이 높아 민감도가 중요한 상황에서 적합하지만 로지스틱 회귀는 정확도와 정밀도가 높고 모델의 안정성이 우수하여 일반적인 분류 문제에서는 로지스틱 회귀가 더 적합한 모델이라고 볼 수 있다.\n",
    "따라서 로지스틱 회귀가 전반적으로 더 일관적이고 신뢰할 수 있는 성능을 보이는 모델로 볼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f4b68a-fc24-420c-8247-c111d8d51701",
   "metadata": {},
   "source": [
    "### 왜 성능 차이가 날까요?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d34101-b7dd-4ed6-9bbe-2d157a449648",
   "metadata": {},
   "source": [
    "두 모델의 성능 차이는 학습 원리와 손실 함수의 구조적 차이에서 비롯된다.\n",
    "선형 회귀는 평균제곱오차를 최소화하여 연속적인 값을 예측하도록 설계된 모델이다. 따라서 분류 문제에 적용할 경우 예측 결과가 확률이 아닌 단순 실수 값으로 출력되며 이를 0과 1로 구분하기 위해 임의적인 cutoff설정이 필요하다. 이러한 특성 때문에 선형 회귀는 예측값의 범위가 제한되지 않고 분류 기준에 따라 결과가 크게 달라질 수 있다.\n",
    "반면, 로지스틱 회귀는 시그모이드 함수를 사용해 예측값을 자연스럽게 0과 1 사이의 확률로 변환한다. 또한 회귀 문제가 아닌 분류 문제에 특화된 로그 손실을 최소화하여 클래스 간의 경계를 보다 안정적이고 일관되게 학습할 수 있다.\n",
    "결국 두 모델의 성능 차이는 선형 회귀가 분류 문제에 부적합한 손실 함수를 사용한다는 점과 로지스틱 회귀가 확률 기반의 최적화 구조를 통해 분류에 최적화되어있다는 점에서 발생한다. 즉, 로지스틱 회귀는 분류 문제에서 해석하기 쉽고 안정적인 결과를 제공하는 반면 선형 회귀는 연속 예측에 적합하지만 분류 문제에서는 근본적인 한계를 갖는다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c027265-c44c-4bef-99e4-285b9f3775c7",
   "metadata": {},
   "source": [
    "### 왜 선형회귀를 분류기로 쓰면 안 될까요?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d064bf-fa15-4ef3-b444-26595ba67af4",
   "metadata": {},
   "source": [
    "선형회귀는 연속적인 값을 예측하기 위한 회귀 분석 기법으로 수치 예측 문제에는 적합하지만 생존 여부 예측과 같은 이진 분류 문제에 적용할 경우 근본적인 한계가 존재한다. \n",
    "첫째, 선형 회귀의 예측값은 -♾️에서 +♾️까지의 연속적인 실수 범위를 가지므로 확률로 해석할 수 없다. 예측값이 -0.3이나 1.5와 같이 비현실적인 값으로 출력될 수 있으며 이는 확률적인 의미를 갖지는 못한다. \n",
    "둘째, 선형 회귀는 출력이 정규화되어 있지 않기 때문에 분류를 위해 임의의 기준값을 설정해야 한다. 그러나 이 기준값의 변화에 따라 모델의 성능이 크게 달라질 수 있어 결정 경계가 불안정하고 일관성이 부족하다.\n",
    "셋째, 선형 회귀의 손실 함수인 평균제곱오차는 연속형 예측 오차를 최소화하는데 초점을 맞추고 있어 클래스 확률을 최적화해야하는 분류 문제에는 부적합하다.\n",
    "마지막으로, 선형 회귀는 MSE손실을 사용하기 때문에 이상치에 매우 민감하다. 극단적인 값이 존재할 경우 전체 회귀선이 크게 왜곡되어 예측 결과가 불안정해질 수 있다. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml_env)",
   "language": "python",
   "name": "ml_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
